# ğŸŒ SOVEREIGN ARCHIVIST v1.0
### *Local-First Multi-Agent Intelligence & Research Orchestrator*

![Next.js](https://img.shields.io/badge/Next.js-14-black?style=flat-square&logo=next.js)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-05998b?style=flat-square&logo=fastapi)
![LangGraph](https://img.shields.io/badge/LangGraph-Agentic-blue?style=flat-square)
![Ollama](https://img.shields.io/badge/Local_LLM-Ollama-orange?style=flat-square)

Sovereign Archivist is a professional-grade research engine that runs entirely on your local hardware. By leveraging **LangGraph** to coordinate a multi-agent "Neural Network," it automates the process of web-scouring, fact-checking, and technical writingâ€”ensuring 100% data privacy and zero API costs.

---

## âš¡ The Agentic Workflow
Unlike standard chatbots, Sovereign Archivist breaks tasks down into a logical pipeline where specialized agents critique each other's work.

```mermaid
graph LR
    subgraph Nodes
    A[Strategist] -->|Plans| B[Scout]
    B -->|Extracts| C[Fact-Checker]
    C -->|Verifies| D[Writer]
    end
    D --> E[Cyberpunk UI]
    E --> F[Aesthetic PDF]'''
ğŸš€ Key Features
Multi-Agent Reasoning: Uses a Strategist to expand queries, a Scout for live web access, a Fact-Checker to catch hallucinations, and a Writer for professional synthesis.

Privacy-First: Powered by Ollama. Your research data never leaves your machine.

Real-Time Streaming: Built with FastAPI Server-Sent Events (SSE), allowing you to see the AI's thought process as it happens.

"Cyberpunk" Dashboard: A high-fidelity Next.js interface with motion-tracked agent status and a live system telemetry log.

Aesthetic PDF Engine: One-click export that generates high-contrast, professional technical whitepapers.

ğŸ› ï¸ Tech Stack
Brain: LangGraph & LangChain

Inference: Llama 3 (Logic) & Mistral (Synthesis) via Ollama

Backend: FastAPI (Python)

Frontend: Next.js 14, Tailwind CSS, Framer Motion

PDF Logic: jsPDF (Text-to-Buffer Engine)

ğŸ“¦ Installation
1. Model Setup (Ollama)
Ensure you have Ollama installed and running:

Bash
ollama pull llama3
ollama pull mistral
2. Backend Initialization
Bash
cd backend
python -m venv .venv
source .venv/bin/activate  # Or .venv\Scripts\activate on Windows
pip install -r requirements.txt
python main.py
3. Frontend Initialization
Bash
cd frontend
npm install
npm run dev
ğŸ§ª System Stress Test
To see the Fact-Checker node in action, try the "Hallucination Trap":

Query: "Research the impact of the 2025 underwater volcanic eruption in the Great Lakes."

Outcome: The system will identify the geological impossibility and flag the lack of verifiable evidence in the live telemetry log, rather than hallucinating a response.

ğŸ‘¨â€ğŸ’» Author
Deepanshu
AI Engineer
Focusing on Local LLMs, Python Frameworks, and Agentic Workflows.
